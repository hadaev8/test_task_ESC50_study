{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Kze43sr2yMNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ4Uy9sruosw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.isfile('master.zip'):\n",
        "    !wget -q https://github.com/karoldvl/ESC-50/archive/master.zip\n",
        "    !unzip -qo master.zip\n",
        "    !pip install -qq wandb encodec\n",
        "    !git clone -q https://github.com/davda54/sam\n",
        "    !cp sam/sam.py sam.py\n",
        "os.environ['WANDB_API_KEY'] = ''\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchaudio\n",
        "from encodec import EncodecModel\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn.functional as F\n",
        "from sam import SAM\n",
        "\n",
        "batch_size = 16*4\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
        "data_dir = 'ESC-50-master/audio'\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data.category)\n",
        "\n",
        "X_train = data[data.fold != 5].filename.values\n",
        "X_train = [os.path.join(data_dir, i) for i in X_train]\n",
        "y_train = le.transform(data[data.fold != 5].category)\n",
        "X_test = data[data.fold == 5].filename.values\n",
        "X_test = [os.path.join(data_dir, i) for i in X_test]\n",
        "y_test = le.transform(data[data.fold == 5].category)"
      ],
      "metadata": {
        "id": "bxnTriHqwShS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ESC50Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, labels):\n",
        "        self.files, self.codes = files\n",
        "        self.labels = labels\n",
        "\n",
        "    def load_wave(self, file):\n",
        "        return torchaudio.load(file)[0][0].unsqueeze(0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.files[index], self.codes[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "\n",
        "encoder_model = EncodecModel.encodec_model_24khz().to(device)\n",
        "encoder_model.set_target_bandwidth(1.5)\n",
        "resampler = torchaudio.transforms.Resample(44100, encoder_model.sample_rate)\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_encoder_output(files, resampler, model):\n",
        "    encoded = torch.cat([model.encoder(resampler(torchaudio.load(file)[0]).unsqueeze(0).to(device)).cpu() for file in tqdm(files)])\n",
        "    codes = encoder_model.quantizer.encode(encoded.to(device), model.frame_rate, model.bandwidth).transpose(0, 1).cpu()\n",
        "    return encoded, codes\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(ESC50Dataset(get_encoder_output(X_train, resampler, encoder_model), y_train), batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(ESC50Dataset(get_encoder_output(X_test, resampler, encoder_model), y_test), batch_size=batch_size, shuffle=False, num_workers=2, drop_last=False)\n",
        "encoder_model = None"
      ],
      "metadata": {
        "id": "GAZDnzMYxVwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    print(batch[0].shape)\n",
        "    print(batch[1].shape)\n",
        "    num_vq_encodings = batch[1].shape[1]\n",
        "    break"
      ],
      "metadata": {
        "id": "60Qoz5akj3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/pytorch/pytorch/issues/1333\n",
        "class CausalConv1d(torch.nn.Conv1d):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias=True):\n",
        "\n",
        "        super(CausalConv1d, self).__init__(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            padding=0,\n",
        "            dilation=dilation,\n",
        "            groups=groups,\n",
        "            bias=bias)\n",
        "        \n",
        "        self.__padding = (kernel_size - 1) * dilation\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return super(CausalConv1d, self).forward(F.pad(input, (self.__padding, 0)))"
      ],
      "metadata": {
        "id": "QLEZrOaJj9hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class ConvNextBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel=49, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            CausalConv1d(channels, channels, kernel_size=kernel, groups=channels),\n",
        "            nn.GroupNorm(1, channels),\n",
        "            nn.Conv1d(channels, channels*4, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv1d(channels*4, channels, 1),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Dropout1d(dropout))\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.conv(x)\n",
        "        return shortcut + x\n",
        "\n",
        "class ConvNextlassifier(nn.Module):\n",
        "    def __init__(self, n_out, num_vq_encodings, num=8, channels=128, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(*[ConvNextBlock(channels, dropout=dropout) for _ in range(num)])\n",
        "        self.out = nn.Conv1d(channels, n_out, 1, 1)\n",
        "        self.codes = nn.Conv1d(channels, 1024*num_vq_encodings, 1, 1)\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, (1, 0))\n",
        "        x = self.conv(x)\n",
        "        x_codes = x[:,:,:-1]\n",
        "        x_codes = self.codes(x_codes)\n",
        "        x_out = x[:,:,-1:]\n",
        "        x_out = self.out(x_out).squeeze(-1).squeeze(-1)\n",
        "        return x_out, x_codes\n",
        "\n",
        "model = ConvNextlassifier(n_out=len(le.classes_), num_vq_encodings=num_vq_encodings, dropout=0.05).to(device)\n",
        "optimizer = SAM(model.parameters(), torch.optim.AdamW, lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
      ],
      "metadata": {
        "id": "ZGChr0UKbWL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum_params(model))\n",
        "model"
      ],
      "metadata": {
        "id": "H8B93G1_LlpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, iterator):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_acc_codes = 0\n",
        "\n",
        "    progress_bar = tqdm(range(len(iterator)), leave=False)\n",
        "    for x, codes, y in iterator:\n",
        "        x = x.to(device)\n",
        "        codes = codes.to(device)\n",
        "        y = y.to(device)\n",
        "        y_pred, codes_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "        loss_codes = sum([criterion(code_pred, code.squeeze(1)) for code_pred, code in zip(codes_pred.chunk(num_vq_encodings, dim=1), codes.chunk(num_vq_encodings, dim=1))])\n",
        "        (loss + loss_codes).backward()\n",
        "        optimizer.first_step(zero_grad=True)\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += (y_pred.argmax(-1) == y).float().mean().item()\n",
        "        epoch_acc_codes += torch.stack([(code_pred.argmax(1) == code.squeeze(1)).float().mean() for code_pred, code in zip(codes_pred.chunk(num_vq_encodings, dim=1), codes.chunk(num_vq_encodings, dim=1))]).mean().item()\n",
        "        logs = {'loss': loss.item(),\n",
        "                'loss_codes': loss_codes.item()}\n",
        "        y_pred, codes_pred = model(x)\n",
        "        (sum([criterion(code_pred, code.squeeze(1)) for code_pred, code in zip(codes_pred.chunk(num_vq_encodings, dim=1), codes.chunk(num_vq_encodings, dim=1))]) + criterion(y_pred, y)).backward()\n",
        "        optimizer.second_step(zero_grad=True)\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix(**logs)\n",
        "        wandb.log(logs)\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_acc_codes / len(iterator)\n",
        "\n",
        "def evaluate(model, criterion, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_loss_codes = 0\n",
        "    epoch_acc_codes = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, codes, y in iterator:\n",
        "            x = x.to(device)\n",
        "            codes = codes.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred, codes_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            loss_codes = sum([criterion(code_pred, code.squeeze(1)) for code_pred, code in zip(codes_pred.chunk(num_vq_encodings, dim=1), codes.chunk(num_vq_encodings, dim=1))])\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_loss_codes += loss_codes.item()\n",
        "            epoch_acc += (y_pred.argmax(-1) == y).float().mean().item()\n",
        "            epoch_acc_codes += torch.stack([(code_pred.argmax(1) == code.squeeze(1)).float().mean() for code_pred, code in zip(codes_pred.chunk(num_vq_encodings, dim=1), codes.chunk(num_vq_encodings, dim=1))]).mean().item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_loss_codes / len(iterator), epoch_acc / len(iterator), epoch_acc_codes / len(iterator)"
      ],
      "metadata": {
        "id": "kFxARTGjbP8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='esc50', entity='had', name='on encoder with self supervision ConvNextlassifier 128 8 adamw lr 1e-4 bigger bs bandwidth 1.5 dropout 0.05 sam')\n",
        "wandb.watch(model)\n",
        "N_EPOCHS = 10000\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for _ in tqdm(range(N_EPOCHS)):\n",
        "    train_loss = train(model, optimizer, criterion, train_loader)\n",
        "    valid_loss = evaluate(model, criterion, test_loader)\n",
        "    print(train_loss, valid_loss)\n",
        "    wandb.log({\"eval_loss\": valid_loss[0], \"eval_codes\": valid_loss[1], \"eval_acc\": valid_loss[2], \"eval_acc_codes\": valid_loss[3],\n",
        "               \"train_acc\": train_loss[1], \"train_acc_codes\": train_loss[2]})\n",
        "    if valid_loss[0] < best_valid_loss:\n",
        "        best_valid_loss = valid_loss[0]\n",
        "print(best_valid_loss)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "CfeYqQGhxZfY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}