{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Kze43sr2yMNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ4Uy9sruosw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.isfile('master.zip'):\n",
        "    !wget -q https://github.com/karoldvl/ESC-50/archive/master.zip\n",
        "    !unzip -qo master.zip\n",
        "    !pip install -qq wandb git+https://github.com/kan-bayashi/ParallelWaveGAN\n",
        "os.environ['WANDB_API_KEY'] = ''\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchaudio\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "batch_size = 16\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data = pd.read_csv('ESC-50-master/meta/esc50.csv')\n",
        "data_dir = 'ESC-50-master/audio'\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(data.category)\n",
        "\n",
        "X_train = data[data.fold != 5].filename.values\n",
        "X_train = [os.path.join(data_dir, i) for i in X_train]\n",
        "y_train = le.transform(data[data.fold != 5].category)\n",
        "X_test = data[data.fold == 5].filename.values\n",
        "X_test = [os.path.join(data_dir, i) for i in X_test]\n",
        "y_test = le.transform(data[data.fold == 5].category)"
      ],
      "metadata": {
        "id": "bxnTriHqwShS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ESC50Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, labels):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "\n",
        "    def load_wave(self, file):\n",
        "        return torchaudio.load(file)[0][0].unsqueeze(0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.load_wave(self.files[index]), self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(ESC50Dataset(X_train, y_train), batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(ESC50Dataset(X_test, y_test), batch_size=batch_size, shuffle=False, num_workers=2, drop_last=False)"
      ],
      "metadata": {
        "id": "GAZDnzMYxVwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    print(batch[0].shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "60Qoz5akj3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "from parallel_wavegan.models.hifigan import HiFiGANScaleDiscriminator\n",
        "\n",
        "class HiFiGANClassifier(torch.nn.Module):\n",
        "    def __init__(self, n_out):\n",
        "        super().__init__()\n",
        "        # downsample_scales from https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/ljspeech/voc1/conf/hifigan.v1.yaml#L71\n",
        "        self.conv = HiFiGANScaleDiscriminator(out_channels=n_out, downsample_scales=[4, 4, 4, 4, 1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)[-1].mean(-1)\n",
        "\n",
        "\n",
        "class ConvNextBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel=49, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(channels, channels, kernel, 1, padding='same', groups=channels),\n",
        "            nn.GroupNorm(1, channels),\n",
        "            nn.Conv1d(channels, channels*4, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv1d(channels*4, channels, 1),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Dropout1d(dropout))\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.conv(x)\n",
        "        return shortcut + x\n",
        "\n",
        "class ConvNextDownBlock(nn.Module):\n",
        "    def __init__(self, channels_in, dropout=0.0):\n",
        "        super().__init__()\n",
        "        channels_out = channels_in * 2\n",
        "        self.down = nn.Sequential(nn.Conv1d(channels_in, channels_out, 4, 4), nn.GroupNorm(1, channels_out))\n",
        "        self.conv = nn.Sequential(ConvNextBlock(channels_out, dropout=dropout),\n",
        "                                  ConvNextBlock(channels_out, dropout=dropout),\n",
        "                                  ConvNextBlock(channels_out, dropout=dropout))\n",
        "    def forward(self, x):\n",
        "        x = self.down(x)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class ConvNextlassifier(nn.Module):\n",
        "    def __init__(self, n_out, num=4, channels=64, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.down = nn.Sequential(nn.Conv1d(1, channels, 16, 16), nn.GroupNorm(1, channels))\n",
        "        self.conv = nn.Sequential(*[ConvNextDownBlock(channels*2**i, dropout) for i in range(num)])\n",
        "        self.out = nn.Conv1d(channels*2**num, n_out, 1, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.down(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.out(x).mean(-1).squeeze(-1)\n",
        "        return x\n",
        "\n",
        "model = HiFiGANClassifier(n_out=len(le.classes_)).to(device)\n",
        "#model = ConvNextlassifier(n_out=len(le.classes_), dropout=0.1).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
      ],
      "metadata": {
        "id": "ZGChr0UKbWL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum_params(model))\n",
        "model"
      ],
      "metadata": {
        "id": "H8B93G1_LlpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, iterator):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    progress_bar = tqdm(range(len(iterator)), leave=False)\n",
        "    for x, y in iterator:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += (y_pred.argmax(-1) == y).sum().item()\n",
        "        logs = {\"loss\": loss.item()}\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix(**logs)\n",
        "        wandb.log(logs)\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / batch_size / len(iterator)\n",
        "\n",
        "def evaluate(model, criterion, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in iterator:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += (y_pred.argmax(-1) == y).sum().item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / batch_size / len(iterator)"
      ],
      "metadata": {
        "id": "kFxARTGjbP8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='esc50', entity='had', name='HiFiGANClassifier')\n",
        "wandb.watch(model)\n",
        "N_EPOCHS = 10000\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for _ in tqdm(range(N_EPOCHS)):\n",
        "    train_loss = train(model, optimizer, criterion, train_loader)\n",
        "    valid_loss = evaluate(model, criterion, test_loader)\n",
        "    print(train_loss, valid_loss)\n",
        "    wandb.log({\"eval_loss\": valid_loss[0], \"eval_acc\": valid_loss[1], \"train_acc\": train_loss[1]})\n",
        "    if valid_loss[0] < best_valid_loss:\n",
        "        best_valid_loss = valid_loss[0]\n",
        "print(best_valid_loss)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "CfeYqQGhxZfY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}